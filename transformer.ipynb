{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96cf5d41-d2a8-47a8-ab74-c1bc5b546062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from einops import rearrange as re\n",
    "from opt_einsum import contract as einsum\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad497467-4596-4f67-980c-676f1aaa521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import (\n",
    "    Module,\n",
    "    ModuleList,\n",
    "    Sequential,\n",
    "    Parameter,\n",
    "    Linear, \n",
    "    Dropout,\n",
    "    LayerNorm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39030dd9-81af-4c70-8567-1994e592bf35",
   "metadata": {},
   "source": [
    "[attn all you need](https://arxiv.org/abs/1706.03762?context=cs)\n",
    "[formal alg transformer](https://arxiv.org/abs/2207.09238)\n",
    "\n",
    "[AI Explained 3D Viz](https://youtu.be/-9vVhYEXeyQ?t=456)\n",
    "\n",
    "[Bloem impl](https://github.com/pbloem/former/blob/master/former/modules.py)\n",
    "[harvard annotated](http://nlp.seas.harvard.edu/annotated-transformer/#encoder-and-decoder-stacks)  \n",
    "[torch mha f](https://github.com/pytorch/pytorch/blob/dcf51885618e7d1d9aa6e628f3354f67ad82b446/torch/nn/functional.py#L4917)   \n",
    "[einops examples](http://einops.rocks/pytorch-examples.html)  \n",
    "\n",
    "[R-Drop](https://arxiv.org/pdf/2106.14448v2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a0df6b-3e48-413a-8b22-30039a880740",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c61cb0-2b8d-4d2d-88a6-9ef6bec3ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "217668ed-d993-4f1f-808a-7b1b1e467b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat(x):\n",
    "    df = pd.DataFrame(x.detach().numpy())\n",
    "    return df.style.background_gradient(cmap='Blues')  # .format('{:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b792655-460a-4a2f-9016-22bfc389a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, n, vocab):\n",
    "        super().__init__()\n",
    "        self.encoder = self.stack(EncoderBlock, 6)\n",
    "        self.decoder = self.stack(DecoderBlock, 6)\n",
    "        self.head = Sequential(\n",
    "            Linear(d_model, vocab.shape[0]),\n",
    "            Softmax(dim=-1)\n",
    "        )\n",
    "       \n",
    "    def forward(src, tgt, src_mask, tgt_mask):\n",
    "        ctx = self.encoder(src, src_mask)\n",
    "        return self.decoder(tgt, ctx, tgt_mask, ctx_mask)\n",
    "   \n",
    "    def stack(Layer, n):\n",
    "        return Sequential([copy.deepcopy(l) for l in Layer()])\n",
    "    \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention()\n",
    "        self.ff = FeedForward()\n",
    "        \n",
    "    def forward(self, x, mask=None): # x -> src?\n",
    "        return self.ff(self.mha(x, mask))\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.masked_mha = MultiHeadAttention()\n",
    "        self.mha = MultiHeadAttention()\n",
    "        self.ff = FeedForward()\n",
    "        \n",
    "    def forward(self, x, ctx=None, mask=None, ctx_mask=None):\n",
    "        x = self.masked_mha(x, mask)\n",
    "        return self.ff(self.mha(x, ctx, ctx, ctx_mask))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model=512, d_ff=2048):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.norm(x + self._ff(x))\n",
    "    \n",
    "    def _ff(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads: int = 8, emb_dim: int = 512):\n",
    "        super().__init__()\n",
    "        assert emb_dim % n_heads == 0  # d_h = d_q = d_k = d_v = emb_dim // n_heads\n",
    "        self.proj_qkv = [Linear(emb_dim, emb_dim, bias=False) for _ in range(3)]\n",
    "        self.proj_o = Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.norm = nn.LayerNorm(emb_dim)\n",
    "        self.h, self.d = n_heads, emb_dim\n",
    "        self.attn = torch.empty((1000 * 8, 256, 256))\n",
    "        self.out = torch.empty((1000 * 8, 256, 64))\n",
    "\n",
    "    def forward(self, q, k=None, v=None, mask=None):\n",
    "        \"\"\" q, k, v: (batch, seq_len, emb_dim) mask: (seq_len, seq_len) \"\"\"\n",
    "        if k is None and v is None:\n",
    "            k = v = q\n",
    "        if mask is None:\n",
    "            mask = torch.zeros((q.shape[-2]))\n",
    "        return self.norm(q + self._mha(q, k, v, mask))\n",
    "    \n",
    "    def _mha(self, q, k, v, mask):\n",
    "        q, k, v = (proj(x) for x, proj in zip((q, k, v), self.proj_qkv))\n",
    "        q, k, v = (re(x, \"b l (h d) -> b h l d\", h=self.h) for x in (q, k, v))\n",
    "        attn = einsum(\"...ij,...kj->...ik\", q, k)\n",
    "        attn = mask + torch.einsum(\"...ij,...kj->...ik\", q, k)\n",
    "        attn = F.softmax(attn / q.shape[-1] ** (1/2), dim=-1)\n",
    "        out = einsum(\"...ij,...jk->...ik\", attn, v)\n",
    "        out = re(out, \"b h n d -> b n (h d)\")\n",
    "        out = self.proj_o(out)\n",
    "        return out\n",
    "\n",
    "    def _mha_infer(self, q, k, v, mask):\n",
    "        with torch.no_grad():\n",
    "            q, k, v = (proj(x) for x, proj in zip((q, k, v), self.proj_qkv))\n",
    "            q, k, v = (re(x, \"b l (h d_h) -> (b h) l d_h\", h=self.h) for x in (q, k, v))\n",
    "            torch.bmm(q, re(k, \"bh l d_h -> bh d_h l\"), out=self.attn)\n",
    "            self.attn += mask\n",
    "            self.attn /= q.shape[-1] ** (1/2)\n",
    "            self.attn = F.softmax(self.attn, dim=-1)\n",
    "            torch.bmm(self.attn, v, out=self.out)\n",
    "            return self.proj_o(re(self.out, \"(b h) l d_h -> b l (h d_h)\", h=self.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23d64f-7625-4e9e-80cc-5d775774eaef",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5b1fe18-6173-43cb-aa3e-e50b069287f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.rand((1_000, 256, 512))\n",
    "mask = torch.triu(torch.full((256, 256), -torch.inf), diagonal=1)\n",
    "mha = MultiHeadAttention()\n",
    "mha.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f18c0-0c62-405d-ae78-6729e4107667",
   "metadata": {},
   "source": [
    "#### _mha vs _mha_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad3e64c-aeee-44a8-942f-a06e9e1ca918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.02 s ± 33.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = mha._mha(emb, emb, emb, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca96857-4056-4c8f-a143-e9fc68221a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.34 s ± 8.96 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = mha._mha_infer(emb, emb, emb, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a32035f1-0a9c-4802-96d9-55dd8e113dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 0.001 s\n",
       "\n",
       "Total time: 3.10783 s\n",
       "File: /var/folders/5y/b092b3m96yb8nglxy9dzqbnr0000gn/T/ipykernel_97173/1043572812.py\n",
       "Function: _mha at line 70\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    70                                               def _mha(self, q, k, v, mask):\n",
       "    71         1        750.6    750.6     24.2          q, k, v = (proj(x) for x, proj in zip((q, k, v), self.proj_qkv))\n",
       "    72         1          0.5      0.5      0.0          q, k, v = (re(x, \"b l (h d) -> b h l d\", h=self.h) for x in (q, k, v))\n",
       "    73         1        406.1    406.1     13.1          attn = einsum(\"...ij,...kj->...ik\", q, k)\n",
       "    74         1        859.3    859.3     27.6          attn = mask + torch.einsum(\"...ij,...kj->...ik\", q, k)\n",
       "    75         1        621.7    621.7     20.0          attn = F.softmax(attn / q.shape[-1] ** (1/2), dim=-1)\n",
       "    76         1        215.5    215.5      6.9          out = einsum(\"...ij,...jk->...ik\", attn, v)\n",
       "    77         1          0.4      0.4      0.0          out = re(out, \"b h n d -> b n (h d)\")\n",
       "    78         1        253.9    253.9      8.2          out = self.proj_o(out)\n",
       "    79         1          0.0      0.0      0.0          return out"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -u 0.001 -f mha._mha mha(emb, emb, emb, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee3cce2-44d2-4ca7-b677-a11b9c293f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 0.001 s\n",
       "\n",
       "Total time: 2.4406 s\n",
       "File: /var/folders/5y/b092b3m96yb8nglxy9dzqbnr0000gn/T/ipykernel_97173/1043572812.py\n",
       "Function: _mha_infer at line 81\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    81                                               def _mha_infer(self, q, k, v, mask):\n",
       "    82         1          0.0      0.0      0.0          with torch.no_grad():\n",
       "    83         1        730.9    730.9     29.9              q, k, v = (proj(x) for x, proj in zip((q, k, v), self.proj_qkv))\n",
       "    84         1        236.3    236.3      9.7              q, k, v = (re(x, \"b l (h d_h) -> (b h) l d_h\", h=self.h) for x in (q, k, v))\n",
       "    85         1        305.5    305.5     12.5              torch.bmm(q, re(k, \"bh l d_h -> bh d_h l\"), out=self.attn)\n",
       "    86         1        149.5    149.5      6.1              self.attn += mask\n",
       "    87         1        147.1    147.1      6.0              self.attn /= q.shape[-1] ** (1/2)\n",
       "    88         1        385.8    385.8     15.8              self.attn = F.softmax(self.attn, dim=-1)\n",
       "    89         1        189.4    189.4      7.8              torch.bmm(self.attn, v, out=self.out)\n",
       "    90         1        296.1    296.1     12.1              return self.proj_o(re(self.out, \"(b h) l d_h -> b l (h d_h)\", h=self.h))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -u 0.001 -f mha._mha_infer mha._mha_infer(emb, emb, emb, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f45895-2166-41f1-84b1-d4efd7dbc988",
   "metadata": {},
   "source": [
    "#### Pytorch [MultiheadAttention.forward](https://github.com/pytorch/pytorch/blob/bbe8d019f280478dc3b143f6988e3e5668499f28/torch/nn/modules/activation.py#L1010) local\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4fbd57a-31b7-4922-984a-ea7c6bad2a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_emb = re(emb, 'b l d -> l b d')\n",
    "bsz, tgt_len, embed_dim = emb.shape\n",
    "num_heads, head_dim = 8, 64\n",
    "in_proj_weight = nn.Parameter(torch.vstack([l.weight for l in mha.proj_qkv]))\n",
    "out_proj_weight = mha.proj_o.weight\n",
    "th_proj_o = Linear(512, 512, bias=False)\n",
    "th_proj_o.weight = out_proj_weight\n",
    "\n",
    "def th_mha():\n",
    "    th_q, th_k, th_v = F._in_projection_packed(th_emb, th_emb, th_emb, in_proj_weight, None)\n",
    "    th_q = th_q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
    "    th_k = th_k.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
    "    th_v = th_v.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
    "    th_out, th_attn = F._scaled_dot_product_attention(th_q, th_k, th_v, mask, 0.0)\n",
    "    th_out = th_out.transpose(0, 1).contiguous().view(tgt_len * bsz, embed_dim)\n",
    "    th_out = th_proj_o(th_out)\n",
    "    th_out = th_out.view(tgt_len, bsz, th_out.size(1))\n",
    "    th_out = mha.norm(th_emb + th_out)\n",
    "    return re(th_out, 'l b d -> b l d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bbfab-22f4-414f-95d4-7a468bb2a046",
   "metadata": {},
   "source": [
    "#### vs. Pytorch F.multi_head_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71e20efa-d1a7-47ca-9eee-d72a98bc1207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.26 s ± 55.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mha_out = mha(emb, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba9bc7d4-0c92-43d6-b5bc-e78ee503c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.03 s ± 53.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "th_out = th_mha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46ee7794-9c82-41d5-8890-06557df907f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 0.001 s\n",
       "\n",
       "Total time: 3.26755 s\n",
       "File: /var/folders/5y/b092b3m96yb8nglxy9dzqbnr0000gn/T/ipykernel_97173/1043572812.py\n",
       "Function: forward at line 62\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    62                                               def forward(self, q, k=None, v=None, mask=None):\n",
       "    63                                                   \"\"\" q, k, v: (batch, seq_len, emb_dim) mask: (seq_len, seq_len) \"\"\"\n",
       "    64         1          0.0      0.0      0.0          if k is None and v is None:\n",
       "    65         1          0.0      0.0      0.0              k = v = q\n",
       "    66         1          0.0      0.0      0.0          if mask is None:\n",
       "    67                                                       mask = torch.zeros((q.shape[-2]))\n",
       "    68         1       3267.5   3267.5    100.0          return self.norm(q + self._mha(q, k, v, mask))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -u 0.001 -f mha.forward mha_out = mha(emb, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b08b0f47-adff-4cbb-8b71-c3eb35d68d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 0.001 s\n",
       "\n",
       "Total time: 3.18376 s\n",
       "File: /var/folders/5y/b092b3m96yb8nglxy9dzqbnr0000gn/T/ipykernel_97173/486783080.py\n",
       "Function: th_mha at line 9\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     9                                           def th_mha():\n",
       "    10         1        754.5    754.5     23.7      th_q, th_k, th_v = F._in_projection_packed(th_emb, th_emb, th_emb, in_proj_weight, None)\n",
       "    11         1         52.4     52.4      1.6      th_q = th_q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
       "    12         1         53.5     53.5      1.7      th_k = th_k.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
       "    13         1        149.7    149.7      4.7      th_v = th_v.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
       "    14         1       1340.6   1340.6     42.1      th_out, th_attn = F._scaled_dot_product_attention(th_q, th_k, th_v, mask, 0.0)\n",
       "    15         1        106.9    106.9      3.4      th_out = th_out.transpose(0, 1).contiguous().view(tgt_len * bsz, embed_dim)\n",
       "    16         1        197.3    197.3      6.2      th_out = th_proj_o(th_out)\n",
       "    17         1          0.0      0.0      0.0      th_out = th_out.view(tgt_len, bsz, th_out.size(1))\n",
       "    18         1        528.6    528.6     16.6      th_out = mha.norm(th_emb + th_out)\n",
       "    19         1          0.1      0.1      0.0      return re(th_out, 'l b d -> b l d')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -u 0.001 -f th_mha th_out = th_mha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "468aaf29-8fb0-468b-94df-5e10aea829c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(mha_out, th_out, atol=1e-6, equal_nan=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
